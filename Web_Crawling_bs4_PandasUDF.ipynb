{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebCrawlingwithbs4andPandasUDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MovieLens Data Enrichment - WebCrawling with bs4 and Pandas UDF"
      ],
      "metadata": {
        "id": "lcbDfsI-kzWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install Pyspark on Google Colab\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "!apt-get -y install openjdk-8-jre-headless\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DWnmDbolDFY",
        "outputId": "125af982-c7a3-485c-b0d1-77ddd13aa206"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  libnss-mdns fonts-dejavu-extra fonts-ipafont-gothic fonts-ipafont-mincho\n",
            "  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "0 upgraded, 1 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 28.2 MB of archives.\n",
            "After this operation, 104 MB of additional disk space will be used.\n",
            "Ign:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u312-b07-0ubuntu1~18.04\n",
            "Err:1 http://security.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u312-b07-0ubuntu1~18.04\n",
            "  404  Not Found [IP: 91.189.91.38 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/universe/o/openjdk-8/openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb  404  Not Found [IP: 91.189.91.38 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 45 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 42.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=284d9f362970a1583ebdcd3fadbd2454ead1b1621fbce973ee8238e6e29e6690\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9wtldDvkl37",
        "outputId": "e919eb53-477e-4234-9662-eb983941924c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "import requests as r\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "BrPT11h8lxF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read links dataset\n",
        "df_links = spark.read.csv(\"/content/drive/My Drive/Colab Notebooks/Recommendation/links.csv\", \\\n",
        "                    header=True, inferSchema=True)\n",
        "# drop the column we do not need\n",
        "df_links = df_links.drop(df_links.tmdbId)\n",
        "# add a partitionId key for pandas UDF to scale up\n",
        "df_links = df_links.withColumn(\"partitionId\", df_links.movieId%100)\n",
        "df_links.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wyWrLw5lxCm",
        "outputId": "35e9c39b-2339-4bfe-ad80-81162f291a5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-----------+\n",
            "|movieId|imdbId|partitionId|\n",
            "+-------+------+-----------+\n",
            "|      1|114709|          1|\n",
            "|      2|113497|          2|\n",
            "|      3|113228|          3|\n",
            "|      4|114885|          4|\n",
            "|      5|113041|          5|\n",
            "+-------+------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([StructField('imdbId', StringType(), True),\n",
        "                     StructField('duration', StringType(), True),\n",
        "                     StructField('n_rating', StringType(), True),\n",
        "                     StructField('n_user_review', StringType(), True),\n",
        "                     StructField('n_critic_review', StringType(), True)\n",
        "                    ]) "
      ],
      "metadata": {
        "id": "m1cdbf_QlxAY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the Pandas UDF \n",
        "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
        "def apply_model(sample_pd: pd.DataFrame)-> pd.DataFrame:\n",
        "\t# get all the imbd id\n",
        "\timdbid_list = list(sample_pd.iloc[:,1])  \n",
        "\tdef tolink(id):\n",
        "\t\treturn \"https://www.imdb.com/title/tt\"+\"0\"*(7-len(str(id)))+str(id)\n",
        "\turl_list = list(map(tolink, imdbid_list))\n",
        "\n",
        "\tcontent = []\n",
        "\tfor i in range(len(url_list)):\n",
        "\t\tresponse = r.get(url_list[i])\n",
        "\t\t# Parse the content of the request with BeautifulSoup\n",
        "\t\tsoup = BeautifulSoup(response.text, 'html.parser')\n",
        "\t\tdcontainers = soup.find_all('div', class_ = 'sc-80d4314-2')\n",
        "\t\tduration = dcontainers[0].find_all('li',class_ = 'ipc-inline-list__item')[-1].text\n",
        "\t\tn_rating = soup.find('div', class_ = 'sc-7ab21ed2-3').text\n",
        "\t\trcontainers = soup.find_all('li', class_ = 'ipc-inline-list__item sc-124be030-1 ghlYSH')\n",
        "\t\tn_user_review = rcontainers[0].find('span', class_ = 'score').text\n",
        "\t\tn_critic_review = rcontainers[1].find('span', class_ = 'score').text\n",
        "\t\tdata = [imdbid_list[i], duration, n_rating, n_user_review, n_critic_review]\n",
        "\t\t# Append the info to the complete dataset\n",
        "\t\tcontent.append(data)\n",
        "\t\t\n",
        "\tmovie_content = pd.DataFrame(content, columns = ['imdbId', 'duration', 'n_rating', 'n_user_review','n_critic_review'])\n",
        "\tmovie_content['imdbId'] = movie_content['imdbId'].astype(str)\n",
        "\tmovie_content['duration'] = movie_content['duration'].astype(str)\n",
        "\tmovie_content['n_rating'] = movie_content['n_rating'].astype(str)\n",
        "\tmovie_content['n_user_review'] = movie_content['n_user_review'].astype(str)\n",
        "\tmovie_content['n_critic_review'] = movie_content['n_critic_review'].astype(str)\n",
        " \n",
        "\treturn movie_content"
      ],
      "metadata": {
        "id": "roaI_FfimAtm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# partition the data and run the UDF\n",
        "fullraw = df_links.groupby(df_links.partitionId).apply(apply_model)\n",
        "fullraw.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C0r07nTmC_z",
        "outputId": "e52f1a57-6a35-4aa8-9b3b-cbf019427763"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/pandas/group_ops.py:102: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+--------+-------------+---------------+\n",
            "|imdbId|duration|n_rating|n_user_review|n_critic_review|\n",
            "+------+--------+--------+-------------+---------------+\n",
            "|115907|  1h 51m|     21K|           70|             50|\n",
            "|110932|  2h 13m|     69K|          184|             67|\n",
            "|107614|   2h 5m|    266K|          325|             60|\n",
            "|110395|  1h 41m|    4.6K|           45|             18|\n",
            "|112368|  1h 30m|    6.8K|           61|             21|\n",
            "+------+--------+--------+-------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert duration to minute\n",
        "def trans_duration(df):\n",
        "  # add new columns\n",
        "  df_result = df.withColumn('hour', substring('duration', 1,1))\\\n",
        "        .withColumn('minute', substring('duration', -3,2))\n",
        "  # change dtypes\n",
        "  df_result = df_result.withColumn(\"hour\",df_result.hour.cast('integer'))\n",
        "  df_result = df_result.withColumn(\"minute\",df_result.minute.cast('integer'))\n",
        "  # duration in minute\n",
        "  df_result = df_result.withColumn('duration', df_result['hour']*60 + df_result['minute']).drop(\"hour\",\"minute\")\n",
        "  return df_result.drop(\"hour\",\"minute\")"
      ],
      "metadata": {
        "id": "OEEwb5gDmE2N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numerical transformation\n",
        "# K -> 1,000\n",
        "# M -> 1,000,000\n",
        "def Kto1000(df, Numbers:str):\n",
        "  df_out = df.withColumn(Numbers, when(col(Numbers).like(\"%K\"), (regexp_replace(Numbers, 'K', '').cast('double')*1000))\\\n",
        "      .when(col(Numbers).like(\"%M\"), (regexp_replace(Numbers, 'M', '').cast('double')*1000000))\\\n",
        "      .when(col(Numbers).like(\"%B\"), (regexp_replace(Numbers, 'B', '').cast('double')*1000000000))\\\n",
        "      .otherwise((regexp_replace(Numbers, ' ', '').cast('double'))))\n",
        "  return df_out"
      ],
      "metadata": {
        "id": "zqPjXaiXmHxz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer(df):\n",
        "  df_tr = trans_duration(df)\n",
        "  df_tr = Kto1000(df_tr, \"n_rating\")\n",
        "  df_tr = Kto1000(df_tr, \"n_user_review\")\n",
        "  df_tr = Kto1000(df_tr, \"n_critic_review\")\n",
        "  return df_tr"
      ],
      "metadata": {
        "id": "0jAnSMwUmJx6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullraw_tr = transfer(fullraw)\n",
        "fullraw_tr.show(5) # 2 minutes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeK79xy1nQix",
        "outputId": "b674d93a-918f-4522-8351-d9f15ee941c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+--------+-------------+---------------+\n",
            "|imdbId|duration|n_rating|n_user_review|n_critic_review|\n",
            "+------+--------+--------+-------------+---------------+\n",
            "|115907|     111| 21000.0|         70.0|           50.0|\n",
            "|110932|     133| 69000.0|        184.0|           67.0|\n",
            "|107614|     125|266000.0|        325.0|           60.0|\n",
            "|110395|     101|  4600.0|         45.0|           18.0|\n",
            "|112368|      90|  6800.0|         61.0|           21.0|\n",
            "+------+--------+--------+-------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ujs6u2XHotfV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}